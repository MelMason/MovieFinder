{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from config2 import omdb_key, tmdb_key, pwrd\n",
    "import warnings\n",
    "from pprint import pprint\n",
    "import re\n",
    "import time\n",
    "from sqlalchemy import create_engine\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create url list for API calls to The Movie Database for the first 500 pages of movies\n",
    "url_list = []\n",
    "\n",
    "\n",
    "for i in range(1,501):\n",
    "    num = i\n",
    "    url = \"https://api.themoviedb.org/3/discover/movie?api_key=\"+tmdb_key+\"&language=en-US&&sort_by=vote_count.desc&include_adult=false&include_video=false&page=\" + str(num)\n",
    "    url_list.append(url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(url_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loop through url's and make API call for each\n",
    "\n",
    "movies_list = []\n",
    "\n",
    "for i in url_list:\n",
    "    r = requests.get(i)\n",
    "    print(r)\n",
    "    r = r.json()\n",
    "    movies_list.append(r[\"results\"])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(movies_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get movies from each page into a list (there are 20 moives per page)\n",
    "m_list = []\n",
    "\n",
    "for i in range(len(movies_list)):\n",
    "    for j in range(20):\n",
    "        m_list.append(movies_list[i][j].items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"There are {len(m_list)} movies in the database\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#put movies in data frame\n",
    "mymovies_df = pd.DataFrame(m_list)\n",
    "mymovies_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rename columns\n",
    "mymovies_df.columns = [\"popularity\", \"tmdb_vote_count\", \"video\", \"poster_path\", \"id\", \"adult\", \"backdrop_path\", \"original_language\", \"original_title\", \"genre_ids\", \"title\", \"vote_average\", \"overview\", \"release_date\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mymovies_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create smaller df with the columns we want\n",
    "short_df = mymovies_df[['original_title','overview']].copy()\n",
    "short_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove tuple from each cell and only show data\n",
    "for x in short_df.columns:\n",
    "    short_df[x] = [y[1] for y in short_df[x]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "short_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create list for json results and url variables for API call\n",
    "movie_jsons = []\n",
    "url1 = \"http://www.omdbapi.com/?t=\"\n",
    "url2 = \"&apikey=\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loop through movies and make API call for each title\n",
    "for movie in short_df[\"original_title\"]:\n",
    "    url = url1 + movie + url2 + omdb_key\n",
    "    response = requests.get(url)\n",
    "    print(response)\n",
    "    response = response.json()\n",
    "    movie_jsons.append(response)\n",
    "    time.sleep(.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " #create dataframe\n",
    "df1 = pd.DataFrame(movie_jsons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set max column view and check dataframe\n",
    "pd.set_option('display.max_columns', 999)\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check data count\n",
    "df1.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop rows that have no ratings\n",
    "df1 = df1[pd.notnull(df1['Ratings'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop rows that have no Box Office\n",
    "df1 = df1[pd.notnull(df1['BoxOffice'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_ratings = [len(data) for data in df1[\"Ratings\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_ratings.count(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove movies that dont have ratings from all 3 sources\n",
    "df1 = df1[df1[\"Ratings\"].map(len)==3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create list of all ratings in the dataframe\n",
    "ratings_list = []\n",
    "for data in df1[\"Ratings\"]:\n",
    "    for i in data:\n",
    "        ratings_list.append(i)\n",
    "ratings_list[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create spearate list for each source\n",
    "imdb = []\n",
    "r_t = []\n",
    "metacritic = []\n",
    "for d in ratings_list:\n",
    "    if d[\"Source\"] == \"Internet Movie Database\":\n",
    "        imdb.append(d[\"Value\"])\n",
    "    elif d[\"Source\"] == \"Rotten Tomatoes\":\n",
    "        r_t.append(d[\"Value\"])\n",
    "    else:\n",
    "        metacritic.append(d[\"Value\"])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check sample list\n",
    "print(len(imdb))\n",
    "print(len(r_t))\n",
    "print(len(metacritic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert strings to floats and ints\n",
    "imdb = [float(x.split(\"/\")[0]) for x in imdb]\n",
    "r_t = [int(x.rstrip(\"%\")) for x in r_t]\n",
    "metacritic = [int(x.split(\"/\")[0]) for x in metacritic]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#check results\n",
    "print(imdb[:5])\n",
    "print(r_t[:5])\n",
    "print(metacritic[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(imdb))\n",
    "print(len(r_t))\n",
    "print(len(metacritic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create new columns\n",
    "df1[\"IMDB\"] = imdb\n",
    "df1[\"Rotten Tomatoes\"] = r_t\n",
    "df1[\"Metacritic\"] = metacritic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check dataframe \n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop unwanted columns\n",
    "df1 = df1.drop([\"Country\", \"DVD\", \"Error\", \"Language\", \"Metascore\", \"Ratings\", \"Response\", \"imdbRating\", \"Website\"], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create variable for regex test\n",
    "string = df1[\"Awards\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test regex code\n",
    "more_wins = re.search(r'(\\d+) win', string)\n",
    "if more_wins:\n",
    "    print(more_wins.group(1))\n",
    "else:\n",
    "    print(\"No more wins\")\n",
    "more_noms = re.search(r'(\\d+) nominations', string)\n",
    "if more_noms:\n",
    "    print(more_noms.group(1))\n",
    "    print(type(more_noms.group(1)))\n",
    "    print(int(more_noms.group(1)))\n",
    "else:\n",
    "    print(\"No more noms\")\n",
    "big_noms = re.search(r'Nominated for (\\d+)', string)\n",
    "if big_noms:\n",
    "    print(big_noms.group(1))\n",
    "    print(type(big_noms.group(1)))\n",
    "else:\n",
    "    print(\"No big noms\")\n",
    "big_wins = re.search(r'Won (\\d+)', string)\n",
    "if big_wins:\n",
    "    print(big_wins.group(1))\n",
    "else:\n",
    "    print(\"No big wins\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create wins and noms list. Prase through \n",
    "\n",
    "wins_list = []\n",
    "noms_list = []\n",
    "\n",
    "for x in df1[\"Awards\"]:\n",
    "    wins = 0\n",
    "    noms = 0\n",
    "    big_wins = re.search(r'Won (\\d+)', x)\n",
    "    if big_wins:\n",
    "        wins += int(big_wins.group(1))\n",
    "    big_noms = re.search(r'Nominated for (\\d+)', x)\n",
    "    if big_noms:\n",
    "        noms += int(big_noms.group(1))\n",
    "    more_wins = re.search(r'(\\d+) win', x)\n",
    "    if more_wins:\n",
    "        wins += int(more_wins.group(1))\n",
    "    more_noms = re.search(r'(\\d+) nominations', x)\n",
    "    if more_noms:\n",
    "        noms += int(more_noms.group(1))\n",
    "    wins_list.append(wins)\n",
    "    noms_list.append(noms)\n",
    "    \n",
    "print(wins_list[:5])\n",
    "print(noms_list[:5])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adds wins and nominations to df1\n",
    "df1[\"Wins\"] = wins_list\n",
    "df1[\"Nominations\"] = noms_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert runtime to int\n",
    "df1[\"Runtime\"] = [int(x.split(\" \")[0]) for x in df1[\"Runtime\"]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop rows that has no imdbVotes\n",
    "df1 = df1[~df1[\"imdbVotes\"].str.contains(\"N/A\")]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert imdbVotes to string\n",
    "df1[\"imdbVotes\"] = [int(x.replace(',','')) for x in df1[\"imdbVotes\"]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check dataframe\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save as csv\n",
    "df1.to_csv(\"data/movies.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
